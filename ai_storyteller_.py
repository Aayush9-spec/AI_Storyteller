# -*- coding: utf-8 -*-
"""AI_Storyteller.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1E8BxjHGBfOPUW1_oMM2i5Ny18JQWZTGa

Day 1: Set up the environment and build my first story from a text prompt

Foundation and Gemini basics
"""

# Commented out IPython magic to ensure Python compatibility.
# @title
# %env GEMINI_API_KEY=os.getenv("GOOGLE_API_KEY")

!pip install -q transformers pillow google-generativeai

from google import genai
import os
client = genai.Client()

if "GEMINI_API_KEY" not in os.environ:
  print("Please set your Gemini API Key in the environment variable GEMINI_API_KEY")
else:
  client=genai.Client()
  MODEL="gemini-2.5-flash"

prompt = input("Enter your story prompt and press enter:\n")
if prompt.strip()=="":
  print("No prompt entered, Exiting")
else:
  print(f"Generating story for prompt: {prompt}")
  print("It may take few seconds")
  try:
    resp= client.models.generate_content(model=MODEL,contents={prompt})
    print("\n-----Generated Story----\n")
    print(resp.text)
  except Exception as e:
    print(f"Error occured while generating story: {e}")

"""Day 2 :"""

!pip install -q transformers pillow google-generativeai timm

from transformers import BlipProcessor, BlipForConditionalGeneration
from PIL import Image
import os
import io

if "GEMINI_API_KEY" not in os.environ:
  print("Please set your Gemini API Key in the environment variable GEMINI_API_KEY")
else:
  client=genai.Client()
  MODEL="gemini-2.5-flash"

processor = BlipProcessor.from_pretrained("Salesforce/blip-image-captioning-large")
model = BlipForConditionalGeneration.from_pretrained("Salesforce/blip-image-captioning-large")

from google.colab import files
uploaded = files.upload()

for fn in uploaded.keys():
  image = Image.open(fn).convert('RGB')
  display(image)

inputs = processor(images = image, return_tensors = 'pt')
out = model.generate(**inputs)

caption = processor.decode(out[0], skip_special_tokens=True)
print("Caption generated by BLIP: ")
print(caption)

story_prompt = (f"Write a short story(around 500-700 words)based on this scene description: {caption}")
print(story_prompt)

print("Sending this to Gemini. \n")

response = client.models.generate_content(model=MODEL, contents=story_prompt)
story = response.text
print("\n----Generated Story----\n")
print(story)

with open("generated_story.txt","w")as f:
    f.write(story)

from google.colab import files
files.download("generated_story.txt")

"""Day 3 :"""

!pip install -q ipywidgets

from google.colab import files
from PIL import Image
import io

uploaded = files.upload()

images=[]
image_names=[]

for name, file in uploaded.items():
  image = Image.open(io.BytesIO(file)).convert('RGB')
  images.append(image)
  image_names.append(name)
  display(image)

from transformers import BlipProcessor, BlipForConditionalGeneration

processor = BlipProcessor.from_pretrained("Salesforce/blip-image-captioning-large")
model = BlipForConditionalGeneration.from_pretrained("Salesforce/blip-image-captioning-large")

captions=[]

for img in images:
  inputs=processor(images=img, return_tensors='pt')
  out=model.generate(**inputs, max_new_tokens=30)
  caption=processor.decode(out[0], skip_special_tokens=True)
  captions.append(caption)

print("Captions generated from images: ")
for i, caption in enumerate(captions):
  print(f"{image_names[i]}: {caption}")

import ipywidgets as widgets
from IPython.display import display, clear_output
tone_dropdown=widgets.Dropdown(
    options=["whimsical", "adventurous", "suspenseful", "romantic", "sci-fi", "mystery"],
    value="sci-fi",
    description="Tone:",
)

length_dropdown=widgets.Dropdown(
    options=["Short(100-200 words)", "Medium(300-500 words)", "Long(600-800 words)"],
    value="Medium(300-500 words)",
    description="Length:",
)

generate_button=widgets.Button(description="Generate Story")
output_box=widgets.Output()

display(tone_dropdown, length_dropdown, generate_button, output_box)

def on_generate_clicked(b):
  with output_box:
    clear_output()

    tone = tone_dropdown.value
    length_map = {
        "Short(100-200 words)": "100-200 words",
        "Medium(300-500 words)": "300-500 words",
        "Long(600-800 words)": "600-800 words",
    }
    length = length_map[length_dropdown.value]

    caption_prompt="\n".join([f"-{c}"for c in captions])

    outline_prompt=(
        f"Using the following scene descriptions, create a 4-chapter story outline.n"
        f"Each chapter should have a title and a short summary.\n\n"
        f"{caption_prompt}\n\nOutline:"
    )

    try:
        outline_response= client.models.generate_content(model=MODEL, contents=outline_prompt)
        outline_text=outline_response.text
        print("Story Outline:\n")
        print(outline_text)

        full_story=""
        for i in range(1, 4):
            chapter_propmt= (
                f"Using the outline below, write Chapter {i} in a {tone} tone."
                f"Make it {length}. Add vivid details, good pacing, and consistent characters.\n\n"
                f"{outline_text}\n\nChapter {i}:"
            )

            chapter_response=client.models.generate_content(model=MODEL, contents=chapter_propmt)
            chapter_text=chapter_response.text
            print(f"\n Chapter {i}:\n")
            print(chapter_text)
            full_story += f"\n\n Chapter {i}:\n{chapter_text}"

        with open("multi_image_story.txt", "w") as f:
            f.write(full_story)
        print("\n\nStory saved to multi_image_story.txt")

        from google.colab import files
        files.download("multi_image_story.txt")

    except Exception as e:
        print(f"Error occured: {e}")

generate_button.on_click(on_generate_clicked)

"""Day 4:"""

!pip install -q gtts reportlab

#Can Paste story here or load from file

story_text ="""
**Chapter 1: The City's Guiding Star**
*   **Summary:** Elias, a young and aspiring musician, often finds himself drawn to the magnificent fountain with a star on top in the heart of the bustling city. He sees it as a symbol of his grandest dreams – a future where his music resonates with thousands, a beacon of the fame and recognition he deeply yearns for. He spends hours observing the city's pulse, imagining the day his own voice will be its vibrant heartbeat.

**Chapter 2: Echoes in Purple Fields**
*   **Summary:** Years later, having achieved some initial success but feeling a growing disconnect from his art, Elias seeks solace outside the city. He travels to a serene field of vibrant purple flowers, where an old, familiar building – a forgotten music academy from his youth – stands in the distance. This place, rich with memories of simpler times and his early inspiration, makes him reflect on the purity of his passion before the pressures of the industry took hold.

**Chapter 3: Beneath the Brightest Light**
*   **Summary:** Elias stands confidently on a grand stage, microphone in hand, bathed in the blinding glare of the spotlights. The crowd before him is a sea of adoring faces, and his music fills the massive venue – he has achieved the stardom he once dreamed of. Yet, amidst the thunderous applause and the culmination of his public ambition, a profound sense of hollowness begins to creep in, making him question the true meaning of his success.

**Chapter 4: The Quiet Melody of Growth**
*   **Summary:** Back in the quiet sanctuary of his own yard, far from the clamor of the stage, Elias tenderly waters a small tree thriving in a pot. This humble tree, a forgotten gift from a past mentor, symbolizes the personal growth and quiet contentment he now seeks. He realizes that true fulfillment isn't found in chasing the distant star of fame, but in nurturing the small, meaningful aspects of his life and finding his most authentic song in the serene beauty of his inner world.
"""

from reportlab.lib.pagesizes import letter
from reportlab.pdfgen import canvas

def export_pdf(text, filename = "story_text"):
    c = canvas.Canvas(filename,pagesize=letter)
    width,height=letter
    text_object=c.beginText(40,height-40)
    text_object.setFont("Helvetica",12)

    for line in text.split('\n'):
        for subLine in[line[i:i+90]for i in range(0,len(line),90)]:
            text_object.textLine(subLine)
    c.drawText(text_object)
    c.save()

export_pdf(story_text, "story.pdf")

from google.colab import files
files.download("story.pdf")

from gtts import gTTS
from IPython.display import Audio, display
from google.colab import files

voices = {
    "Default English (US Female)": {"lang": "en", "tld": "com"},
    "British Accent (UK Female)": {"lang": "en", "tld": "co.uk"},
    "Australian Accent (AU Female)": {"lang": "en", "tld": "com.au"},
    "Slow Reading Voice:": {"lang": "en", "tld": "com", "slow": True}
}

for label,options in voices.items():
    print(f"Generating Audio:{label}")

    tts=gTTS(
        text=story_text,
        lang=options.get("lang", "en"),
        slow=options.get("slow", False),
        tld=options.get("tld", "com"),
    )

    filename = f"{label.replace(' ', '_').lower()}.mp3"

    tts.save(filename)

    display(Audio(filename = filename,autoplay=False))

    files.download(filename)

"""Day 5 :"""

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app_streamlit_story.py
# import streamlit as st  #Web app framwork
# from PIL import Image
# import io, requests, os
# import textwrap
# from gtts import gTTS   #Translate text to speech
# from transformers import BlipProcessor, BlipForConditionalGeneration
# from reportlab.pdfgen import canvas
# from reportlab.lib.pagesizes import A4
# from reportlab.lib.utils import ImageReader
# from pyngrok import ngrok
# import tempfile
# import google.generativeai as genai
# import torch
# 
# 
# #Authentication
# NGROK_AUTH_TOKEN = "32hLm5H2cwiE9gSy984wwfCsViA_5LvdDm5jh5UgnkYCgrKFz"
# BACKGROUND_IMAGE_URL = "https://i.postimg.cc/RFBqmzjg/i5.jpg"
# GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
# 
# 
# #Streamlit Page Setup/Style
# st.set_page_config(page_title="StoryTeller", layout="wide")
# 
# 
# st.markdown(
# 
#    f"""
# 
#    <style>
# 
#    .stApp {{
# 
#        background-image: url("{BACKGROUND_IMAGE_URL}");
# 
#        background-size: cover;
# 
#        background-attachment: fixed;
# 
#    }}
# 
#    section[data-testid="stSidebar"] {{
# 
#        background: rgba(0,0,0,0.3);
# 
#        backdrop-filter: blur(10px);
# 
#        border-radius: 12px;
# 
#        padding: 10px;
# 
#    }}
# 
#    div[data-testid="stFileUploader"] {{
# 
#        background: rgba(255,255,255,0.2);
# 
#        border-radius: 10px;
# 
#        padding: 10px;
# 
#    }}
# 
#    html, body, h1, h2, h3, h4, h5, h6, p, div, span, label, li, input, textarea {{
# 
#        color: #93A8AC !important;
# 
#    }}
# 
#    .stButton>button, .stDownloadButton>button {{
# 
#        color: #93A8AC !important;
# 
#        border-color: #93A8AC;
# 
#    }}
# 
#    </style>
# 
#    """,
# 
#    unsafe_allow_html=True
# 
# )
# 
# st.title("Multi-Image AI Storyteller")
# st.markdown("Upload images -> Generate Story -> Export as PDF & MP3")
# 
# with st.sidebar:
# 
#    tone = st.selectbox("Tone", ["Adventurous", "Whimsical", "Romantic", "Mysterious", "Humorous", "Calm"])
# 
#    length_label = st.selectbox("Length", ["Short (200-300 words)", "Medium (300-600 words)", "Long (600-1000 words)"])
# 
#    start_ngrok = st.checkbox("Start ngrok tunnel")
# 
#    if start_ngrok:
# 
#        ngrok.set_auth_token(NGROK_AUTH_TOKEN)
# 
#        url = ngrok.connect(8501)
# 
#        st.success(f"Public URL: {url}")
# 
# 
# 
# 
# uploaded_images = st.file_uploader("Upload multiple images", type=["jpg", "jpeg", "png"], accept_multiple_files=True)
# 
# 
# #Caption Model
# @st.cache_resource
# def load_models():
#    processor = BlipProcessor.from_pretrained("Salesforce/blip-image-captioning-large")
#    model = BlipForConditionalGeneration.from_pretrained("Salesforce/blip-image-captioning-large").to("cuda" if torch.cuda.is_available() else "cpu")
#    return processor, model
# 
# 
# processor, blip_model = load_models()
# 
# 
# #Config Gemini
# genai.configure(api_key=GEMINI_API_KEY)
# 
# @st.cache_resource
# def load_gemini_model():
#    return genai.GenerativeModel(model_name="models/gemini-2.5-flash")
# 
# gemini_model = load_gemini_model()
# 
# 
# #Captioning The Images
# def get_captions(images):
#     captions =[]
#     for img in images:
#         if img.mode != "RGB":
#             img = img.convert("RGB")
#         inputs = processor(images=img, return_tensors="pt").to(blip_model.device)
#         out = blip_model.generate(**inputs)
#         caption = processor.decode(out[0], skip_special_tokens=True)
#         captions.append(caption)
#     return captions
# 
# 
# def generate_story(captions, tone, length_label):
#    length_map = {
#        "Short (200-300 words)": (200, 300, 800),
#        "Medium (300-600 words)": (300, 600, 1200),
#        "Long (600-1000 words)": (600, 1000, 1600)
#    }
#    min_words, max_words, max_tokens = length_map.get(length_label, (300, 600, 1200))
# 
#    prompt = (
#     f"You are a creative writer. Write a {tone.lower()} story based on the following image captions:\n\n"
#     + "\n".join([f"- {cap}" for cap in captions])
#     + f"\n\nThe story should be vivid, engaging, and emotionally rich, with a coherent beginning, middle, and end."
#     + f"\nMake it approximately between {min_words} and {max_words} words long."
#    )
# 
#    try:
#        response = gemini_model.generate_content(
#            contents=prompt,
#            generation_config=genai.GenerationConfig(
#                temperature=0.9,
#                top_p=0.95,
#                max_output_tokens=max_tokens
#            )
#        )
#        return response.text.strip()
#    except Exception as e:
#        return f"❌ Error generating story: {e}"
# 
# 
# #PDF Generation
# def create_pdf(story_text, images):
#    buffer = io.BytesIO()
#    c = canvas.Canvas(buffer, pagesize=A4)
#    w, h = A4
# 
#    try:
#        bg_img = Image.open(requests.get(BACKGROUND_IMAGE_URL, stream=True).raw).convert("RGB")
#        bg = ImageReader(bg_img)
#        c.drawImage(bg, 0, 0, width=w, height=h)
#    except:
#        pass
# 
#    c.setFont("Helvetica-Bold", 16)
#    c.drawString(50, h - 50, "Generated Story")
# 
#    text = textwrap.wrap(story_text, 100)
#    y = h - 80
#    for line in text:
#        if y < 80:
#            c.showPage()
#            y = h - 80
#        c.drawString(50, y, line)
#        y -= 15
# 
# 
#    if images:
#        c.showPage()
#        c.setFont("Helvetica-Bold", 16)
#        c.drawString(50, h - 50, "Uploaded Images")
#        x, y = 50, h - 150
#        for img in images:
#            img.thumbnail((200, 200))
#            c.drawImage(ImageReader(img), x, y, width=img.width, height=img.height)
#            x += 220
#            if x > w - 200:
#                x = 50
#                y -= 220
# 
#    c.save()
#    buffer.seek(0)
#    return buffer
# 
# 
# #Audio Generation
# def create_audio(story):
#    audio_bytes = io.BytesIO()
#    tts = gTTS(story)
#    tts.write_to_fp(audio_bytes)
#    audio_bytes.seek(0)
#    return audio_bytes
# 
# 
# #Processing part
# if st.button("Generate Story") and uploaded_images:
#    pil_images = [Image.open(img) for img in uploaded_images]
#    with st.spinner("Generating captions..."):
#        captions = get_captions(pil_images)
#        for i, cap in enumerate(captions):
#            st.write(f"**Image {i+1}**: {cap}")
# 
#    with st.spinner("Generating story..."):
#        story = generate_story(captions, tone, length_label)
#        st.success("Story generated!")
#        st.write(story)
# 
#    with st.spinner("Creating PDF..."):
#        pdf_file = create_pdf(story, pil_images)
#        st.download_button("📄 Download Story as PDF", data=pdf_file, file_name="story.pdf", mime="application/pdf")
# 
#    with st.spinner("Creating Audio..."):
#        audio = create_audio(story)
#        st.audio(audio)
#        st.download_button("🔊 Download Story as MP3", data=audio, file_name="story.mp3", mime="audio/mpeg")
# elif not uploaded_images:
#    st.warning("Upload at least one image to begin.")

ngrok.kill()

!pip install -q streamlit pyngrok transformers torch gtts reportlab Pillow


!streamlit run app_streamlit_story.py --server.port 8501 &>/content/log.txt &


from pyngrok import ngrok

ngrok.set_auth_token("32hLm5H2cwiE9gSy984wwfCsViA_5LvdDm5jh5UgnkYCgrKFz")

url = ngrok.connect(8501)

print("Public URL:", url)
